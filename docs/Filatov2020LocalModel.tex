\documentclass[12pt, twoside]{article}
\usepackage{jmlda}
\newcommand{\hdir}{.}

\begin{document}

\title
    [Исследование свойств локальных моделей] % краткое название; не нужно, если полное название влезает в~колонтитул
    {Исследование свойств локальных моделей в задаче декодирования сигналов головного мозга}
\author
[] % список авторов (не более трех) для колонтитула; не нужен, если основной список влезает в колонтитул
{} % основной список авторов, выводимый в оглавление
[Филатов А.В., Маркин В.О.] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\email
{filatov.av@phystech.edu; markin.vo@phystech.edu}
\organization
{МФТИ}
\abstract
    {
		В данной работе рассматривается проблема создания нейрокомпьютерного интерфейса. Особенностью этой проблемы является требование устойчивости у моделей. При построении систем нейрокомпьютерного интерфейса используются линейные модели. Важным аспектом создания таких моделей является построение надежного
		% определение оптимальности (и заменить надежность)
		% заменить декодирование на multiway декодирование
		% стабильность (устойчивость)
		 признакового пространства. В данной статье рассматривается построение признакового пространства на данных электрокортикограммы для метода частичной регрессии наименьших квадратов
		
		Основной вклад данной работы заключается в учете пространственной зависимости в модели. В нашем подходе используется пространственная аппроксимация искомого сигнала с помощью нормального распределения и полиномов. Информация об аппроксимации учитывается при создании признакового пространства. В статье приведены результаты численных экспериментов на данных электрокортикограмм головного мозга обезъян.
		
\bigskip
\noindent
\textbf{Ключевые слова}: \emph {отбор признаков; нейрокомпьютерный интерфейс; электрокортикограмма; локальные модели }
}

\maketitle
\section{Введение}
Нейрокомпьютерный интерфейс (BCI) \cite{shih2012brain} 
считывает сигналы нейронов головного мозга, анализировать их   и переводить в команды исполняющей системы. Исследования в данной области позволяют людям с нарушениями двигательных функций организма заменить или восстановить их. Примером такой системы является система управления роботизированным протезом посредством мозговых импульсов. 

Мозговая активность представляет собой совокупность электрических импульсов различной амплитуды и частоты, возникающих на поверхности головного мозга. Исследование мозговой активности производится при помощи  электрокортикографии \cite{hill2012recording} или \cite{aminoff2012electroencephalography} электроэнцефалографии. В результате измерения мы получаем временной ряд напряжений сигнала, который используется как данные для задачи. В задаче используется данные из \cite{chao2010long}.

 Подходы \cite{morishita2014brain, alexander2013traveling} к решению задачи состоят в извлечении информативных признаков из пространственных, частотных и временных характеристик сигнала . 
В \cite{chin2007identification, eliseyev2014stable, loza2017unsupervised} исследуются частотные характеристики. Основными методами решения являются PLS \cite{eliseyev2014stable,eliseyev2016penalized, rosipal2005overview}, PCA \cite{rosipal2005overview, eliseyev2016penalized}. В \cite{zhao2014coupled} используются алгоритмы, построенные на скрытых марковских моделях. В \cite{loza2017unsupervised, zhao2010ecog} рассматриваются различные участки сигнала в виде слов. В работе \cite{motrenko2018multi} задача отбора признаков сводится к задаче квадратичного программирования (QuadraticProgramming Feature Selection \cite{rodriguez2010quadratic}). Также для решения задачи используются нейросетевые модели\cite{xie2018deep}. 
\newpage
\section{Постановка задачи}
Данные электрокортикограммы представляют собой временной ряд амплитуд сигналов $\mathbf{X}(t)  \in \RR^{m}$, по которым нужно предсказать положение запястья в следующим момент времени $\mathbf{y}(t+1) \in \RR^3$. В качестве выборки рассматривается $\mathfrak{D} = \{(\vec{X}_{(i)}^n, \mathbf{y_{i+1}}\}$, где $\vec{X}_{(i)}^n$ --- значения временнего ряда с момента времени $i$ по момент $i + n$, где $n$ --- гиперпараметер задачи и выбирается из дополнительных условий. В силу коррелированности исходных данных предлагается разбить предсказательную модель на локальную модель и модель регрессии.

\begin{Def}
	Локальная модель --- совокупность двух параметрических отображений: $\phi$ и $\psi$, где 
	$\phi$ отображает из пространства большей размерности в пространство меньшей размерности, а $\psi$ отображает из этого же пространства меньшей размерности в исходное пространство большей размерности.
\end{Def}

В нашем случае под количеством информации понимается дисперсия.
Оптимизационная задача на нахождение локальной модели ставится следующим образом
\[
	\phi: \RR^{n \times k_1} \rightarrow \RR^{n \times k_2}
\]
\[
	\psi: \RR^{n \times k_2} \rightarrow \RR^{n \times k_1}
\]
\[
	\psi^*, \phi^* = \argmin_{\psi, \phi} \|\vec{X} - \psi \circ \phi (\vec{X}) \|_2
\]

Локальная модели получаем новую выборку $\mathfrak{D}_{new} = \{(\vec{Z}_{(i)}^{n}, \vec{y}_i)\}$, $\vec{Z}_{(i)}^{n} = \phi(\vec{X}_{(i)}^{n})$. Эту задачу мы решаем при помощи регрессии:
\[
	\vec{w}^* = \argmin_{\vec{w}} L(\mathbf{z}, \vec{w}, \mathbf{y})
\]

Критерием качества линейной модели выступают коэффициент детерминации и корреляция Пирсона.


\section{Вычислительный эксперимент}
Основная цель --- сравнение моделей результатов моделей с и без использования локальных моделей
\subsection{План работы}
\begin{itemize}
\item Подготовить данные
\item Применить локальную модель к данным
\item Подать выход локальной модели на вход PLS
\item Получить результаты
\item Получить результаты без использования локальной модели 
\item Сравнить результаты
\end{itemize}
\subsection{Данные}
В качестве данных для проведения вычислительного эксперимента использовались данные \cite{chao2010long}, представляющие запись электрокортикограммы головного мозга обезьяны. Каждой записи соответствует амплитуды напряжения на 32 электродах и 3 пространственные координаты.
При проведении эксперимента выборка была сокращена в 10 раз.

Обработка исходных данных производится в несколько этапов и подробно описано в статье \cite{zhao2010ecog}. Исходный сигнал записан на частоте $1$ кГц, данные о движении — на частоте $120 $ Гц. Сигнал фильтруется полосным фильтром с диапазоном от $0.3$ до $600 $ Гц. Затем для каждого момента времени $t$ строится частотно-временная
характеристика. Над сигналом в окне $[t - 1.1s, t]$ с шагом в $\Delta$ = $100$ миллисекунд осуществляется вейвлет-преобразование на $10$ различных частотах $\omega_j$ в диапазоне от $10$ до $150$ Гц. Затем строится матрица $10 \times 10$, элементами которой $s_{ij}$ является квадрат амплитуды на частоте $\omega_j$ в момент времени $t - (1 + i)\Delta$. Таким образом, размер описания одного объекта (момента времени) составляет $N_{ch} \times 10 \times 10$.

При проведении эксперимента разбиение выборки производится в следующем соотношении: 80\% --- обучение, 20\% --- тестирование.

\subsection{Алгоритм}
%\subsubsection{Локальная модель}
%Пусть заданы координаты каждого электрода на плоскости $Z = \{(z_j) \in \RR^2, j \in {1, \ldots N_{ch}} \}$. Зафиксируем произвольный момент времени m, частоту f и задержку t.
%Обозначим sj = X(j,f,t)
%m . Физический смысл sj – амплитуда сигнала на электроде j.Будем
%строить аппроксимирующую модель как функцию плотности двумерного нормального
%распределения. Локальная модель сигнала определяться выборочным средним и выборочной ковариацией координат электродов с весами, равными амплитуде.
%В качестве новых признаков для описания сигнала используются параметры нормального распределения , , а так же их производные по времени
%Так как матрица ковариации симметрична, то новое признаковое описание имеет вид


\subsubsection{Метод частичных квадратов (PLS)}

Метод частичных наименьших квадратов проецирует матрицу плана $\vec{X}$ и целевую
 матрицу $\vec{Y}$ в скрытое пространство малой размерностью $l$ $(l < M)$. Метод PLS находит в скрытом пространстве матрицы $\vec{T}, \vec{U} \in \RR
^{m\times l}$, которые лучше всего описывают оригинальные матрицы $\vec{X}$ и $\vec{Y}$. При этом PLS максимизирует взаимосвязь между $\vec{T}$ и $\vec{U}$.
Матрица плана $\vec{X}$ и целевая матрица $\vec{Y}$ проецируются в скрытое пространство следующим образом:
\begin{equation*}
\begin{split}
\underset{m\times n
}{\vec{X}}= \underset{m\times l}{\vec{T}} \cdot \underset{l\times n
}{\vec{P}^T}
+ \underset{m\times n}{\vec{F}}
=
\sum_{k=1}^{l}
\underset{m\times 1}{\vec{t}_k}
\cdot\underset{1\times n}{\vec{p}^T_k}
+ \underset{m\times n}{\vec{F}}
, 
\\ 
\underset{m\times r}{\vec{Y}}
= \underset{m\times l}{\vec{U}} \cdot \underset{l\times r
}{\vec{Q}^T}
+ \underset{m\times r
}{\vec{E}}= \sum_{k=1}^l
\underset{m\times 1}{\vec{u}_k} \cdot \underset{1\times r}{\vec{q}^T_k}
+ \underset{m\times r}{\vec{E}}.
\end{split}
\end{equation*}

Здесь $\vec{T}$ и $\vec{U}$ – образы исходных матриц в скрытом пространстве, причём столбцы матрицы
$\vec{T}$ ортогональны; $\vec{P}$ и $\vec{Q}$ – матрицы перехода; $\vec{E}$ и $\vec{F}$ – матрицы остатков. Метод PLS
максимизирует линейную зависимость между столбцами матриц $\vec{T}$ и $\vec{U}$
\[\vec{U} \approx \vec{TB}, \vec{B} = diag(\beta_k), \quad \beta_k = \vec{u}^T_k 
\vec{t}_k/(\vec{t}^T_k\vec{
t}_k).
\]

\subsection{Результаты}
\newpage
.
\newpage
.
\newpage
\bibliographystyle{unsrt}
\bibliography{references}
\end{document}
